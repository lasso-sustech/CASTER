<!DOCTYPE html>
<html>
<head>
  <!-- <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <!-- <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/> -->
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <!-- <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/> -->


  <!-- <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG"> -->
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <!-- <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image"> -->
  <!-- Keywords for your paper to be indexed by-->
  <!-- <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE"> -->

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">CASTER: A Computer-Vision-Assisted Wireless
              Channel Simulator for Gesture Recognition</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://renzhenyu.site" target="_blank">Zhenyu Ren</a><sup>1</sup>,</span>
                <span class="author-block">
                  Guoliang Li<sup>2</sup>,</span>
                  <span class="author-block">
                    Chenqing Ji<sup>1</sup>,
                  </span>
                  <span class="author-block">
                    Chao Yu<sup>1</sup>,
                  </span>
                  <span class="author-block">
                    <a href="https://bearswang.github.io" target="_blank">Shuai Wang</a><sup>3</sup>,
                  </span>
                  <span class="author-block">
                    <a href="http://lasso.eee.sustech.edu.cn" target="_blank">Rui Wang</a><sup>1,*</sup>
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block"><sup>1</sup>Southern University of Science and Technology (SUSTech)
                    <br><sup>2</sup>University of Macau, <sup>3</sup>Chinese Academy of Science
                      <!-- <br>Conference name and year -->
                    </span>
                    <span class="eql-cntrb"><br><sup>*</sup>Corresponding author: Prof. Rui Wang (<a href="mailto:wang.r@sustech.edu.cn">wang.r@sustech.edu.cn</a>)</span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/2311.07169.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                    <!-- Supplementary PDF link -->
                    <!-- <span class="link-block">
                      <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span> -->

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/rzy0901/testSpectrogram" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2311.07169" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser video-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video poster="" id="tree" autoplay controls muted loop height="100%">
        <!-- Your video here -->
        <source src="static/videos/hand.mp4"
        type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        Hand gesture channel simulation demo with experiment verification. 
      </h2>
      <video poster="" id="tree" autoplay controls muted loop height="100%">
        <!-- Your video here -->
        <source src="static/videos/human.mp4"
        type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        Human motion channel simulation demo with experiment verification (Future Work).
      </h2>
    </div>
  </div>
</section>
<!-- End teaser video -->

<!-- <!== Video carousel ==>
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-video1">
          <video poster="" id="video1" autoplay controls muted loop height="100%">
            <!== Your video file here ==>
            <source src="static/videos/hand.mp4"
            type="video/mp4">
          </video>
          <h2 class="subtitle has-text-centered">
            Hand gesture channel simulation demo with experiment verification using CASTER. 
          </h2>
        </div>
        <div class="item item-video2">
          <video poster="" id="video2" autoplay controls muted loop height="100%">
            <!== Your video file here ==>
            <source src="static/videos/human.mp4"
            type="video/mp4">
          </video>
          <h2 class="subtitle has-text-centered">
            Human motion channel simulation demo with experiment verification (Future Work). 
          </h2>
        </div>
      </div>
    </div>
  </div>
</section>
<!== End video carousel ==> -->



<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            In this paper, a computer-vision-assisted simulation
            method is proposed to address the issue of training dataset
            acquisition for wireless hand gesture recognition. In the existing
            literature, in order to classify gestures via the wireless channel
            estimation, massive training samples should be measured in
            a consistent environment, consuming significant efforts. In the
            proposed CASTER simulator, however, the training dataset can
            be simulated via existing videos. Particularly, in the channel
            simulation, a gesture is represented by a sequence of snapshots,
            and the channel impulse response of each snapshot is calculated
            via tracing the rays scattered off a primitive-based hand model.
            Moreover, CASTER simulator relies on the existing video clips to
            extract the motion data of gestures. Thus, the massive measurements of wireless channel can be eliminated. The experiments
            first demonstrate an 83.0% average recognition accuracy of
            simulation-to-reality inference in recognizing 5 categories of
            gestures. Moreover, this accuracy can be boosted to 96.5% via
            the method of transfer learning.            
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<!-- https://player.bilibili.com/ -->
<!-- Youtube video -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <!-- Paper video. -->
      <h2 class="title is-3">Real-time gesture recognition demo (in Chinese).</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          
          <div class="publication-video">
            <!-- Youtube embed code here -->
            <!-- <iframe src="https://www.youtube.com/embed/JkaxUblCGz0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe> -->
            <iframe src="//player.bilibili.com/player.html?bvid=BV14G411y7nn&t=39" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"></iframe>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End youtube video --> 

<!-- Image carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Gallery of CASTER.</h2>
        <div id="results-carousel" class="carousel results-carousel">
          <div class="item">
            <img src="static/images/simulation_and_exp.png" alt="simulation_and_exp.png""/>
            <h2 class="subtitle has-text-centered">
              Illustration of the simulation (top) and experimental (bottom) setup of CASTER.
            </h2>
          </div>
            <div class="item">
              <img src="static/images/dataset_new2.png" alt="dataset_new2.png"/>
              <h2 class="subtitle has-text-centered">
                This illustration presents both the simulated and experimental datasets derived from CASTER, with a selection of spectrograms depicted for clarity. Our experimental dataset comprises real spectrograms, calculated from received mmWave signals. On the other hand, our simulated dataset is produced by the innovative CASTER simulator. This simulator processes video clips as input, extracts the motion data of gestures, and simulates the channel impulse response for each snapshot by tracing the rays that scatter off a primitive-based hand model. The final step involves applying the Short Time Fourier Transform (STFT) to yield the simulated spectrograms.
              </h2>
            </div>
            <div class="item">
              <img src="static/images/gesture_recognition_result.png" alt="gesture_recognition_result.png"/>
              <h2 class="subtitle has-text-centered">
                Gesture recognition results of CASTER. 
              </h2>
              </div>
        </div>
</div>
</div>
  <!-- <div id="results-carousel" class="carousel results-carousel">
  <div class="item">
    <!== Your image here ==>
    <img src="static/images/dataset_new2.png" alt="MY ALT TEXT"/>
    <h2 class="subtitle has-text-centered">
      Illustration of the simulated and experimental dataset from CASTER, where some examples of spectrogram are plotted.
    </h2>
  </div>
  </div> -->
</section>
<!-- End image carousel -->

<!-- Paper poster -->
<!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>

      <iframe  src="static/pdfs/sample.pdf" width="100%" height="550">
          </iframe>
        
      </div>
    </div>
  </section> -->
<!--End paper poster -->

<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX citation</h2>
      <pre><code>
        @article{ren2023caster,
          title={CASTER: A Computer-Vision-Assisted Wireless Channel Simulator for Gesture Recognition},
          author={Ren, Zhenyu and Li, Guoliang and Ji, Chenqing and Yu, Chao and Wang, Shuai and Wang, Rui},
          journal={arXiv preprint arXiv:2311.07169},
          year={2023}
        }
      </code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-10">
        <div class="content">
          <smalL>
          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          </smalL>
        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
